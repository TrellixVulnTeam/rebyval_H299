experiment:

  context:
    name: "001"
    experiment_type: rebyval 
    log_path: ./log

  main_loop_control:
    warmup_stage:
      target_model_samples: 0 # train 10 taget model and collect validation weight.
    target_samples_per_iter: 0
    main_loop_times: 0

  target_trainer:
    dataloader:
      name: cifar10 # default cifar10
      trainer_dataset_path: ~/.keras/dataset/cifar10 # default using keras
      batch_size: 256
    model:
      name: dnn # default dnn
      deep_dims: 128,128,64,32,10 # default 128,64,64,32
      activations_for_all: relu,relu,relu,relu,softmax # default relu
    loss:
      name: SparseCategoricalCrossentropy
      identifier:
        class_name: SparseCategoricalCrossentropy
        config:
          from_logits: True
      metric: accuracy
    optimizer:
      name: Adam # default SGD
      learning_rate: 0.0001 # default 0.01
      scheduler: None # default None
    train_loop_control:
      train:
        check_should_train: True
        max_training_steps: 100000 # default 10000
        max_training_epochs: 100 # default 10
      valid:
        check_should_valid: True # default False for no validation step
        valid_gap: 100 # default 1000 training steps
        valid_steps: 10 # default valid for 100 steps
        analyse:
            format: tensor
        partition: 5
        log_path: ./log
        save_model:
          save_in: "001" # or name as your wish
          save_after_step: 1000 # save latest and best model per 1000 steps
      test:
        test_steps: 50
        check_should_test: True # default False for no test step

  surrogate_trainer:
    dataloader:
      name: dnn_weights
      datapath: ./log/analyse
      sample_of_curves: 30
      format: tensor
      batch_size: 256
      num_trainable_variables: 10
    model:
      name: dnn # default dnn
      deep_dims: 256,128,64,64,32,1
      activations_for_all: relu,relu,relu,relu,relu,softplus
#      restore_model:
#        restore_model_dir: surroagte/001
#        restore_from: model_best # or best, default None
    optimizer:
      name: SGD
      learning_rate: 0.01
      scheduler:
        name: linear_scaling_with_warmup # default None
        scaling_factor: 1
    loss:
      name: MeanSquaredError
      metric: MeanSquaredLogarithmicError
    train_loop_control:
      train:
        check_should_train: True
        max_training_steps: 100000 # default inf
        max_training_epochs: 100 # default inf
      valid:
        check_should_valid: True # default False for no validation step
        valid_gap: 1000 # default 1000 training steps
        valid_steps: 100 # default valid for 100 steps
        log_path: ./log/surrogate/SR_layer6_bz256_sgd001
        save_model:
          save_in: surroagte/001 # or name as your wish, default None
          save_after_step: 1000 # save latest and best model per 1000 steps
      test:
        test_steps: 500
        check_should_test: True # default False for no test step

